{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "EUCLID is a method for discovering material models from heterogeneous data. In this notebook, we will use EUCLID to discover hyperelastic material models from synthetically generated FEM data. Using synthetically generated data has the advantantage that we know the ground truth material model used for generating the data and that we can control the noise level of the data. The full EUCLID code for discovering hyperelastic material models is available under https://github.com/EUCLID-code/EUCLID-hyperelasticity. Here, however, we will not consider the full code, but consider a minimal working example.\n",
        "\n",
        "\n",
        "```\n",
        "#    ________ ___  ___ _______ ___     ___ ______\n",
        "#   /  _____//  / /  //  ____//  /    /  //  _   \\\n",
        "#  /  _____//  /_/  //  /___ /  /___ /  //  /_|  |\n",
        "# /_______//_______//______//______//__//_______/\n",
        "# Efficient Unsupervised Constitutive Law Identification and Discovery\n",
        "# https://euclid-code.github.io/\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "G3lDhbO2riFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load python libraries\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YRcRvqeyppNW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUGiIOT7nOqx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import linear_model\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global variables\n"
      ],
      "metadata": {
        "id": "-0vbxHycedfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim = 2\n",
        "numNodesPerElement = 3\n",
        "voigtMap = [[0,1],[2,3]]\n",
        "linkToData = 'https://raw.githubusercontent.com/EUCLID-code/EUCLID-hyperelasticity/refs/heads/main/FEM_data/plate_hole_1k/plate_hole_1k_NeoHookeanJ2/'\n",
        "loadsteps = [10,20,30,40]\n",
        "lambda_r = 100"
      ],
      "metadata": {
        "id": "kR_KOjbsejBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classes for organizing data"
      ],
      "metadata": {
        "id": "JUCO_8qDxeSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Reaction:\n",
        "    def __init__(self, dofs, force):\n",
        "        self.force = force\n",
        "        self.dofs = dofs"
      ],
      "metadata": {
        "id": "RCZL65IHxiks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subroutines for computing kinematic quantities\n",
        "Note that plane strain is assumed. This means that F13 = F23 = 0 and F33 = 1. We do not explicitly implement these values."
      ],
      "metadata": {
        "id": "IqixwOOTzN_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computeCauchyGreenStrain(F):\n",
        "    F11 = F[:,0:1]\n",
        "    F12 = F[:,1:2]\n",
        "    F21 = F[:,2:3]\n",
        "    F22 = F[:,3:4]\n",
        "    C11 = F11**2 + F21**2\n",
        "    C12 = F11*F12 + F21*F22\n",
        "    C21 = F11*F12 + F21*F22\n",
        "    C22 = F12**2 + F22**2\n",
        "    C = torch.cat((C11,C12,C21,C22),dim=1)\n",
        "    return C\n",
        "\n",
        "def computeJacobian(F):\n",
        "    F11 = F[:,0:1]\n",
        "    F12 = F[:,1:2]\n",
        "    F21 = F[:,2:3]\n",
        "    F22 = F[:,3:4]\n",
        "    J = F11*F22 - F12*F21\n",
        "    return J\n",
        "\n",
        "def computeStrainInvariants(C):\n",
        "    C11 = C[:,0:1]\n",
        "    C12 = C[:,1:2]\n",
        "    C21 = C[:,2:3]\n",
        "    C22 = C[:,3:4]\n",
        "    I1 = C11 + C22 + 1.0\n",
        "    I2 = C11 + C22 - C12*C21 + C11*C22\n",
        "    I3 = C11*C22 - C12*C21\n",
        "    return I1, I2, I3\n",
        "\n",
        "def computeStrainInvariantDerivatives(F,i):\n",
        "    F11 = F[:,0:1]\n",
        "    F12 = F[:,1:2]\n",
        "    F21 = F[:,2:3]\n",
        "    F22 = F[:,3:4]\n",
        "    dIdF = torch.zeros(F.shape[0],F.shape[1])\n",
        "    if(i==1):\n",
        "        # dI1/dF:\n",
        "        dIdF = 2.0*F\n",
        "    elif(i==2):\n",
        "        # dI2/dF:\n",
        "        dIdF11 = 2.0*F11 - 2.0*F12*F21*F22 + 2.0*F11*(F22**2)\n",
        "        dIdF12 = 2.0*F12 + 2.0*F12*(F21**2) - 2.0*F11*F21*F22\n",
        "        dIdF21 = 2.0*F21 + 2.0*(F12**2)*F21 - 2.0*F11*F12*F22\n",
        "        dIdF22 = 2.0*F22 - 2.0*F11*F12*F21 + 2.0*(F11**2)*F22\n",
        "        dIdF = torch.cat((dIdF11,dIdF12,dIdF21,dIdF22),dim=1)\n",
        "    elif(i==3):\n",
        "        # dI3/dF:\n",
        "        J = F11*F22 - F12*F21\n",
        "        dIdF11 = 2.0*F22 * J\n",
        "        dIdF12 = -2.0*F21 * J\n",
        "        dIdF21 = -2.0*F12 * J\n",
        "        dIdF22 = 2.0*F11 * J\n",
        "        dIdF = torch.cat((dIdF11,dIdF12,dIdF21,dIdF22),dim=1)\n",
        "    else:\n",
        "        raise ValueError('Incorrect invariant index')\n",
        "    return dIdF"
      ],
      "metadata": {
        "id": "6zLOkBRtzQBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subroutines for computing features and their derivatives\n",
        "Note that, under plane strain, the invariants fulfill the relationship I2 = (I1 + I3 âˆ’ 1). Therefore, the features and thus the strain energy density function can be considered as functions of I1 and I3 only."
      ],
      "metadata": {
        "id": "QrneOzAM1KAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def computeFeatures(I1, I2, I3):\n",
        "    K1 = I1 * torch.pow(I3,-1/3) - 3.0\n",
        "    K2 = (I1 + I3 - 1) * torch.pow(I3,-2/3) - 3.0\n",
        "    J = torch.sqrt(I3)\n",
        "    numFeatures = 3\n",
        "    Q = torch.zeros(I1.shape[0],numFeatures)\n",
        "    Q[:,0:1] = K1\n",
        "    Q[:,1:2] = K2\n",
        "    Q[:,2:3] = (J-1)**2\n",
        "    return Q\n",
        "\n",
        "def getNumberOfFeatures():\n",
        "    return computeFeatures(torch.zeros(1,1),torch.zeros(1,1),torch.zeros(1,1)).shape[1]\n",
        "\n",
        "def differentiateFeaturesWithInvariants(features,I):\n",
        "    d_feature_dI = torch.zeros(features.shape[0],features.shape[1])\n",
        "    for i in range(features.shape[1]):\n",
        "        temp = torch.autograd.grad(features[:,i:(i+1)],I,torch.ones(I.shape[0],1),create_graph=True,allow_unused=True)[0]\n",
        "        if(type(temp)!=type(None)):\n",
        "            d_feature_dI[:,i:(i+1)] = temp\n",
        "    return d_feature_dI\n",
        "\n",
        "def assembleFeatureDerivative(d_features_dI1,d_features_dI3,dI1dF,dI3dF,ele):\n",
        "    d_features_dI1_element = d_features_dI1[ele,:]\n",
        "    d_features_dI3_element = d_features_dI3[ele,:]\n",
        "    dI1dF_element = dI1dF[ele,:]\n",
        "    dI3dF_element = dI3dF[ele,:]\n",
        "    d_features_dF_element = np.outer(d_features_dI1_element,dI1dF_element)+np.outer(d_features_dI3_element,dI3dF_element)\n",
        "    return d_features_dF_element"
      ],
      "metadata": {
        "id": "Mp5knjMq1Llr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subroutines for array manipulations"
      ],
      "metadata": {
        "id": "mQrpOGux861h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assembleB(gradNa,ele):\n",
        "    B_element = np.zeros((dim*dim,dim*numNodesPerElement))\n",
        "    for a in range(numNodesPerElement):\n",
        "        dN1 = gradNa[a][ele,0]\n",
        "        dN2 = gradNa[a][ele,1]\n",
        "        B_element[:,2*a:2*a+2] = np.array([(dN1,0.0),(dN2,0.0),(0.0,dN1),(0.0,dN2)])\n",
        "    return B_element\n",
        "\n",
        "def assembleGlobalVector(vector_global,vector_element,connectivity,ele):\n",
        "    # Adds a vector defined at an element to the corresponding position in the global vector.\n",
        "    for a in range(numNodesPerElement):\n",
        "        vector_global[2*connectivity[a][ele]] += vector_element[2*a]\n",
        "        vector_global[2*connectivity[a][ele]+1] += vector_element[2*a+1]\n",
        "    return vector_global\n",
        "\n",
        "def assembleGlobalMatrix(matrix_global,matrix_element,connectivity,ele):\n",
        "    for a in range(numNodesPerElement):\n",
        "        matrix_global[2*connectivity[a][ele],:] += matrix_element[2*a,:]\n",
        "        matrix_global[2*connectivity[a][ele]+1,:] += matrix_element[2*a+1,:]\n",
        "    return matrix_global\n",
        "\n",
        "def zipper(matrix):\n",
        "    vector = np.zeros(2*matrix.shape[0], dtype=type(matrix[0,0]))\n",
        "    for i in range(matrix.shape[0]):\n",
        "        vector[2*i] = matrix[i,0:1]\n",
        "        vector[2*i+1] = matrix[i,1:2]\n",
        "    return vector"
      ],
      "metadata": {
        "id": "a5Xr2HPq88Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data from GitHub repository and assemble linear equations\n",
        "\n",
        "An exemplary dataset can be found on GitHub under https://github.com/EUCLID-code/EUCLID-hyperelasticity. We directly load the data from there.\n",
        "\n",
        "The data was generated using FEM simulations of a plate with a hole made of a hyperelastic material. The data contains information about the mesh, the Gauss points, the displacements and the reaction forces for four time steps."
      ],
      "metadata": {
        "id": "b-imAs7Lpmr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_free = []\n",
        "b_free = []\n",
        "A_reaction = []\n",
        "b_reaction = []\n",
        "\n",
        "for idx_step, step in enumerate(loadsteps):\n",
        "\n",
        "    # Step 1: Load data\n",
        "    print('Load data for the ' + str(idx_step+1) + '. load step...')\n",
        "    url = linkToData + str(step)\n",
        "    df = pd.read_csv(url + '/output_nodes.csv',dtype=np.float64)\n",
        "    x_nodes = torch.tensor(df[['x','y']].values)\n",
        "    u_nodes = torch.tensor(df[['ux','uy']].values)\n",
        "    bcs_nodes = torch.tensor(df[['bcx','bcy']].round().astype(int).values)\n",
        "    dirichlet_nodes = (bcs_nodes!=0)\n",
        "    df = pd.read_csv(url + '/output_reactions.csv',dtype=np.float64)\n",
        "    reactions = []\n",
        "    for i in range(torch.max(bcs_nodes).item()):\n",
        "        reactions.append(Reaction(bcs_nodes == (i+1),df['forces'][i]))\n",
        "    df = pd.read_csv(url + '/output_elements.csv',dtype=np.float64)\n",
        "    connectivity = []\n",
        "    for i in range(numNodesPerElement):\n",
        "        connectivity.append(torch.tensor(df['node'+str(i+1)].round().astype(int).tolist()))\n",
        "    df = pd.read_csv(url + '/output_integrator.csv',dtype=np.float64)\n",
        "    gradNa = []\n",
        "    for i in range(numNodesPerElement):\n",
        "        gradNa.append(torch.tensor(df[['gradNa_node'+str(i+1)+'_x','gradNa_node'+str(i+1)+'_y']].values))\n",
        "    qpWeights = torch.tensor(df['qpWeight'].values)\n",
        "\n",
        "    numNodes = x_nodes.shape[0]\n",
        "    numElements = connectivity[0].shape[0]\n",
        "\n",
        "    # Step 2: Compute kinematic quantities (deformation gradient, right Cauchy-green stretch, invariants)\n",
        "    print('Compute kinematic quantities for the ' + str(idx_step+1) + '. load step...')\n",
        "    u = []\n",
        "    for i in range(numNodesPerElement):\n",
        "        u.append(u_nodes[connectivity[i],:])\n",
        "    F=torch.zeros(numElements,4)\n",
        "    for a in range(numNodesPerElement):\n",
        "        for i in range(dim):\n",
        "            for j in range(dim):\n",
        "                F[:,voigtMap[i][j]] += u[a][:,i] * gradNa[a][:,j]\n",
        "    F[:,0] += 1.0\n",
        "    F[:,3] += 1.0\n",
        "    J = computeJacobian(F)\n",
        "    C = computeCauchyGreenStrain(F)\n",
        "    I1, I2, I3 = computeStrainInvariants(C)\n",
        "    dI1dF = computeStrainInvariantDerivatives(F,1)\n",
        "    dI2dF = computeStrainInvariantDerivatives(F,2)\n",
        "    dI3dF = computeStrainInvariantDerivatives(F,3)\n",
        "\n",
        "    # Step 3: Compute features and their derivatives\n",
        "    print('Compute features for the ' + str(idx_step+1) + '. load step...')\n",
        "    I1.requires_grad = True\n",
        "    I2.requires_grad = True\n",
        "    I3.requires_grad = True\n",
        "    features = computeFeatures(I1, I2, I3)\n",
        "    d_features_dI1 = differentiateFeaturesWithInvariants(features,I1)\n",
        "    d_features_dI2 = differentiateFeaturesWithInvariants(features,I2)\n",
        "    d_features_dI3 = differentiateFeaturesWithInvariants(features,I3)\n",
        "\n",
        "    # Step 4: Convert torch tensors to numpy arrays\n",
        "    x_nodes = x_nodes.cpu().detach().numpy()\n",
        "    u_nodes = u_nodes.cpu().detach().numpy()\n",
        "    dirichlet_nodes = dirichlet_nodes.cpu().detach().numpy()\n",
        "    qpWeights = qpWeights.cpu().detach().numpy()\n",
        "    for i in range(len(reactions)):\n",
        "        reactions[i].dofs = reactions[i].dofs.cpu().detach().numpy()\n",
        "    for i in range(len(connectivity)):\n",
        "        connectivity[i] = connectivity[i].cpu().detach().numpy()\n",
        "    for i in range(len(gradNa)):\n",
        "        gradNa[i] = gradNa[i].cpu().detach().numpy()\n",
        "    F = F.cpu().detach().numpy()\n",
        "    J = J.cpu().detach().numpy()\n",
        "    C = C.cpu().detach().numpy()\n",
        "    I1 = I1.cpu().detach().numpy()\n",
        "    I2 = I2.cpu().detach().numpy()\n",
        "    I3 = I3.cpu().detach().numpy()\n",
        "    dI1dF = dI1dF.cpu().detach().numpy()\n",
        "    dI2dF = dI2dF.cpu().detach().numpy()\n",
        "    dI3dF = dI3dF.cpu().detach().numpy()\n",
        "    features = features.cpu().detach().numpy()\n",
        "    d_features_dI1 = d_features_dI1.cpu().detach().numpy()\n",
        "    d_features_dI2 = d_features_dI2.cpu().detach().numpy()\n",
        "    d_features_dI3 = d_features_dI3.cpu().detach().numpy()\n",
        "\n",
        "    # Step 5: Assemble linear equations\n",
        "    print('Assemble linear equations for the ' + str(idx_step+1) + '. load step...')\n",
        "    numFeatures = features.shape[1]\n",
        "    LHS = np.zeros((dim*numNodes,numFeatures))\n",
        "    for ele in range(numElements):\n",
        "        d_features_dF_element = assembleFeatureDerivative(d_features_dI1,d_features_dI3,dI1dF,dI3dF,ele)\n",
        "        B_element = assembleB(gradNa,ele)\n",
        "        LHS_element = np.transpose(B_element).dot(np.transpose(d_features_dF_element)) * qpWeights[ele]\n",
        "        LHS = assembleGlobalMatrix(LHS,LHS_element,connectivity,ele)\n",
        "\n",
        "    non_dirichlet_nodes = ~(zipper(dirichlet_nodes)) # ~ can cause errors -> use np.logical_not\n",
        "    LHS_free = LHS[non_dirichlet_nodes,:]\n",
        "    RHS_free = np.zeros(LHS_free.shape[0])\n",
        "    LHS_fix = np.zeros([len(reactions),LHS_free.shape[1]])\n",
        "    RHS_fix = np.zeros(len(reactions))\n",
        "    reaction_counter = -1\n",
        "    for reaction in reactions:\n",
        "        reaction_counter += 1\n",
        "        one_vector = np.ones(LHS[zipper(reaction.dofs),:].shape[0])\n",
        "        LHS_fix[reaction_counter] = np.transpose(one_vector).dot(LHS[zipper(reaction.dofs),:])\n",
        "        RHS_fix[reaction_counter] = reaction.force\n",
        "\n",
        "    A_free.append(LHS_free)\n",
        "    b_free.append(RHS_free)\n",
        "    A_reaction.append(LHS_fix)\n",
        "    b_reaction.append(RHS_fix)\n"
      ],
      "metadata": {
        "id": "wwXcXAUrnVIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5076b493-e145-4496-8e58-c18fb93eaecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load data for the 1. load step...\n",
            "Compute kinematic quantities for the 1. load step...\n",
            "Compute features for the 1. load step...\n",
            "Assemble linear equations for the 1. load step...\n",
            "Load data for the 2. load step...\n",
            "Compute kinematic quantities for the 2. load step...\n",
            "Compute features for the 2. load step...\n",
            "Assemble linear equations for the 2. load step...\n",
            "Load data for the 3. load step...\n",
            "Compute kinematic quantities for the 3. load step...\n",
            "Compute features for the 3. load step...\n",
            "Assemble linear equations for the 3. load step...\n",
            "Load data for the 4. load step...\n",
            "Compute kinematic quantities for the 4. load step...\n",
            "Compute features for the 4. load step...\n",
            "Assemble linear equations for the 4. load step...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Concatenate all linear equations"
      ],
      "metadata": {
        "id": "EZqqwQubNlm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_free_all = np.concatenate(A_free, axis=0)\n",
        "b_free_all = np.concatenate(b_free, axis=0)\n",
        "A_reaction_all = np.concatenate(A_reaction, axis=0)\n",
        "b_reaction_all = np.concatenate(b_reaction, axis=0)\n",
        "\n",
        "A = np.concatenate((A_free_all,np.sqrt(lambda_r)*A_reaction_all), axis=0)\n",
        "b = np.concatenate((b_free_all,np.sqrt(lambda_r)*b_reaction_all), axis=0)"
      ],
      "metadata": {
        "id": "Ll9hug8_NrfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EUCLID"
      ],
      "metadata": {
        "id": "x6dJ1wIxQMmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = linear_model.Lasso(alpha=0.0001)\n",
        "lasso.fit(A,b)\n",
        "print(lasso.coef_)"
      ],
      "metadata": {
        "id": "5GHxOoluPMLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2598c8ee-562e-40ae-aa06-b028f56271f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.49835751 0.         1.49943368]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "klJjFQIFdPRy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}